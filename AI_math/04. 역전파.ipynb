{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝은 기울기값 $\\frac{\\partial\\mathscr{L}(\\mathbf{W})}{\\partial \\mathbf{W}}$ 를 계산할 때 역전파 알고리즘을 사용한다. 기울기값은 출력층에서부터 역방향으로 chain rule에 의하여 순차대로 전달된다. 다음과 같은 2층 신경망이 있다고 가정할 때, 순전파를 수식으로 표현하면 다음과 같다.\n",
    "\n",
    "<img src='img/neural_net.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 입력 $x$가 첫 linear layer 통과 : $\\mathbf{z}=\\mathbf{W}^{(1)} \\mathbf{x}+\\mathbf{b}^{(1)}$\n",
    "2. 활성화 함수 통과 : $\\mathbf{h}=\\sigma(\\mathbf{z})$\n",
    "3. 두번째 linear layer 통과 : $\\mathbf{y}=\\mathbf{W}^{(2)} \\mathbf{h}+\\mathbf{b}^{(2)}$\n",
    "4. 출력으로부터 Loss $\\mathscr{L}$ 계산 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역전파 알고리즘을 이용해 각 층의 gradient를 구할 수 있다. 아래는 $\\mathbf{W}^{(1)}$의 gradient를 구하는 과정이다. \n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{W}^{(1)}} \\mathcal{L}=\\left(\\nabla_{\\mathbf{W}^{(1)} \\mathbf{z}}\\right)\\left(\\nabla_{\\mathbf{z}} \\mathbf{h}\\right)\\left(\\nabla_{\\mathbf{h}} \\mathbf{o}\\right)\\left(\\nabla_{\\mathbf{0}} \\mathcal{L}\\right) \\longleftrightarrow \\frac{\\partial \\mathcal{L}}{\\partial W_{i j}^{(1)}}=\\sum_{l, r, k} \\frac{\\partial \\mathcal{L}}{\\partial o_{l}} \\frac{\\partial o_{l}}{\\partial h_{r}} \\frac{\\partial h_{r}}{\\partial z_{k}} \\frac{\\partial z_{k}}{\\partial W_{i j}^{(1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loss 함수로부터 2층 출력 $\\mathbf{y}$에 대한 gradient 계산\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial\\, y_{l}}\n",
    "$$\n",
    "\n",
    "2. 전달받은 $\\frac{\\partial \\mathcal{L}}{\\partial\\, y_{l}}$로부터 $\\mathbf{h}$에 대한 gradient 계산\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial\\,h_{r}} =\n",
    "\\sum_l \\frac{\\partial \\mathcal{L}}{\\partial y_{l}} \\frac{\\partial y_{l}}{\\partial h_{r}} =\n",
    "\\sum_l \\frac{\\partial \\mathcal{L}}{\\partial y_{l}}W_{r l}^{(2)}\n",
    "$$\n",
    "\n",
    "3. 전달받은 $\\frac{\\partial \\mathcal{L}}{\\partial\\,h_{r}}$ 로부터 $\\mathbf{z}$에 대한 gradient 계산\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial\\,z_{k}} =\n",
    "\\sum_r \\frac{\\partial \\mathcal{L}}{\\partial h_{r}} \\frac{\\partial h_{r}}{\\partial z_{k}} =\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial h_{k}} \\frac{\\partial h_k}{\\partial z_{k}} =\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial h_{k}} \\sigma'(z_k)\n",
    "$$\n",
    "\n",
    "4. 전달받은 $\\frac{\\partial \\mathcal{L}}{\\partial\\,z_{k}}$ 로부터 최종적으로 $\\mathbf{W}^{(1)}$ 에 대한 gradient 계산\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W_{i j}^{(1)}} = \n",
    "\\sum_{k} \\frac{\\partial \\mathcal{L}}{\\partial\\,z_{k}} \\frac{\\partial\\,z_{k}}{\\partial W_{i j}^{(1)}} =\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial\\,z_{j}} x_{ji}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 과정을 요약하면 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W_{i j}^{(1)}} = \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial\\,z_{j}} x_{ji} =\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial h_{j}} \\sigma'(z_j)x_{ji} =\n",
    "\\sum_l \\frac{\\partial \\mathcal{L}}{\\partial y_{l}}W_{j l}^{(2)}\\sigma'(z_j)x_{ji}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
