{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 X에 대해서 관찰되는 레이블 Y이 있다고 할 때, 우리가 목표로 하는 모델 $f$는 다음과 같이 나타낼 수 있다.\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0,\\sigma_\\epsilon)\n",
    "$$\n",
    "\n",
    "우리가 일반적으로 원하는 것은 우리가 훈련시킨 $\\hat{f}$ 가 데이터 x에 대해서 레이블 Y와의 오차를 최소화하는 것이다.\n",
    "\n",
    "$$\n",
    "Err(x) = E\\left[(Y-\\hat{f}(x))^2\\right]\n",
    "$$\n",
    "\n",
    "이는 수학적으로 다음과 같이 Bias term, Variance term, Noise term으로 decompose된다.\n",
    "\n",
    "$$\n",
    "Err(x) = \\left(E[\\hat{f}(x)]-f(x)\\right)^2 + E\\left[\\left(\\hat{f}(x)-E[\\hat{f}(x)]\\right)^2\\right] +\\sigma_e^2\\\\\n",
    "Err(x) = \\mathrm{Bias}^2 + \\mathrm{Variance} + \\mathrm{Irreducible\\ Error}\n",
    "$$\n",
    "\n",
    "Bias와 Variance의 가지는 의미는 다음과 같다.\n",
    "\n",
    "* Bias : $\\hat{f(x)}$ 가 참값 $f(x)$와 평균적으로 어느정도 차이가 있는지에 대한 term이다. 여기서 평균이라 함은 각각 다른 데이터샘플을 가지고 훈련시킨 여러 $\\hat{f(x)}$에 대한 평균이다.\n",
    "\n",
    "* Variance : 여러 데이터샘플로 훈련된 $\\hat{f}$들이 예측하는 $\\hat{f(x)}$ 어느정도 흩어져 있는지를 나타내는 term이다.\n",
    "\n",
    "<img src = 'img/bias_variance.png' width=50% />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅱ. Cross Validation\n",
    "\n",
    "모델을 최적화하는 과정에서 $Err(x)$ 를 줄이기 위해서는 Bias Error와 Variance Error를 줄여야하지만 일반적으로 이 둘은 tradeoff 관계를 갖는다. 보통 Model complexity를 증가시키는 방향으로 모델을 조정하면 Variance Error가 증가하고, 반대의 경우에는 Bias Error가 증가한다. 따라서 우리의 목표는 적절한 sweet spot을 찾는 것이다.\n",
    "\n",
    "<img src = 'img/bias_variance_tradeoff.png' width=50% />\n",
    "\n",
    "아쉽게도 이 sweet spot을 수치적으로 찾는 것은 많은 경우 불가능할 것이다. 대신 우리는 train set에 포함되지 않는 validation set을 사용하여 예측되는 오차를 구하여 이 오차를 최소화하는 방향으로 모델을 조정한다. 때로는 하나의 validation set만을 사용하는 것만으로느 정확한 오차를 예측하는데에 부족할 수 있다. 따라서 전체 train data 하나의 여러 K개의 partition으로 나누어 하나를 validation set으로, 나머지를 train set으로 학습시켜 오차를 계산하는 방식을 각 partition에 대해 K번 반복하여 얻은 오차들의 평균을 사용하는 방법을 사용할 수 있다. 이를 K fold cross validation이라고 한다.\n",
    "\n",
    "<img src = 'img/cross_validation.jpg' width=70% />\n",
    "\n",
    "Sequential 데이터에 대해서는 조금의 변형이 필요한데 밑에 링크에 자세히 나와있다.\n",
    "\n",
    "https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅲ. Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 기법은 훈련데이터 $\\mathscr{D}$ 에서 Bootstrap 샘플링을 통해 얻은 데이터 $\\mathscr{D}_n$ 로 훈련시킨 약 분류기(Weak Classifier) $f$를 여러개 결합하여 강 분류기(Strong Classifier) $F$ 를 만드는 것이다. \n",
    "\n",
    "$$\n",
    "F(x;\\mathscr{D}) = \\sum_{n=1}^N w_n f(x;\\mathscr{D}_n)\n",
    "$$\n",
    "\n",
    "### Bagging\n",
    "\n",
    "각 약 분류기를 독립적으로 parallel하게 훈련시켜 평균 혹은 투표를 통해 최종 예측을 한다. 즉 $w_n$ 이 모두 같다. 평균을 취함으로써 결국 variance를 줄이는 것이므로 일반적으로 Low bias, high variance를 가지는 약 분류기를 사용한다. 가장 대표적인 예로 완전결정트리를 약 분류기로 사용하는 랜덤포레스트 모델이 있다.\n",
    "\n",
    "<img src='img/bagging.png' width=60%/>\n",
    "\n",
    "### Boosting\n",
    "\n",
    "Bagging과는 다르게 각 약 분류기는 parallel이 아닌 sequential하게 훈련된다는 특징을 갖는다. 각 약 분류기는 이전 분류기들이 잘 못 예측한 데이터들에 가중치를 더 주어 학습된다. Boosting 기법은 약 분류기가 low variance, high bias일때 많이 쓰이며 결과적으로 보통 더 낮은 bias를 갖는 강 분류기를 얻게 된다. Boosting 알고리즘을 쓰는 예로 Gradient boost, XG boost 등이 있다.\n",
    "\n",
    "<img src='img/boosting.png' width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고\n",
    "\n",
    "* http://scott.fortmann-roe.com/docs/BiasVariance.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
