{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. Einsum 이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특수한 표기법을 통해 다양한 텐서 연산을 수행할 수 있는 함수로 numpy, pytorch에서 다음과 같이 사용할 수 있다.\n",
    "```python\n",
    "np.einsum('ix,jx->ij', A, B)\n",
    "torch.einsum('ix,jx->ij', [A, B])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅱ. Einsum 표기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 다음과 같은 식이 있을 때,\n",
    "\n",
    "$$\n",
    "C_{mqn} = \\sum_t\\sum_k A_{ntkm}B_{kq} = A_{ntkm}B_{kq}\n",
    "$$\n",
    "\n",
    "notation은 `'ntkm,kq->mqn'` 이다. 연산 방식은 2가지만 기억하면 된다.\n",
    "\n",
    "1. Input에서의 겹치는 인덱스는 elementwise multiplication를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = [1,2,3]\n",
    "b = [1,2,3]\n",
    "\n",
    "np.einsum('i, i -> i', a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Output에 나오지 않은 인덱스는 그 축의 방향으로 summation이 이루어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  6,  9, 12])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [1,2]\n",
    "\n",
    "np.einsum('i, j -> i', a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For문을 사용하여 표현하면 다음과 같이 Outer Loop 과 Inner Loop으로 나뉜다..\n",
    "\n",
    "1. Free Indices : output에 나오는 인덱스 (m, q, n)\n",
    "2. Summation Indices : 그 외 인덱스 (t, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(2*3*4*5).reshape(2, 3, 4, 5)\n",
    "B = np.arange(4*7).reshape(4, 7)\n",
    "\n",
    "N, T, K, M = A.shape\n",
    "K, Q = B.shape\n",
    "\n",
    "C = np.zeros((M, Q, N))\n",
    "\n",
    "# Free indices\n",
    "for m in range(M):\n",
    "    for q in range(Q):\n",
    "        for n in range(N):\n",
    "            \n",
    "            # Summation indices\n",
    "            C[m, q, n] = np.sum([A[n, t, k, m] * B[k, q] for t in range(T) for k in range(K)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einsum을 사용하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_ = np.einsum('ntkm, kq -> mqn', A, B)\n",
    "\n",
    "np.all(C_ == C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅲ. Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 5, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor(3, 5, 7)\n",
    "\n",
    "torch.einsum('ijk -> kji', t).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "torch.einsum('ij -> ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Column Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 12.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "torch.einsum('ij -> j', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Row Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  7., 11.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "torch.einsum('ij -> i', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Matrix Vector Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 11.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "x = torch.Tensor([1, 2])\n",
    "\n",
    "torch.einsum('ik, k -> i', A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22., 28.],\n",
       "        [49., 64.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "B = torch.Tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "torch.einsum('ik, kj -> ij', A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([1, 2, 3])\n",
    "\n",
    "torch.einsum('i, i -> ', a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Hadamard Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.,  9.],\n",
       "        [16., 25., 36.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "B = torch.Tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "torch.einsum('ij, ij -> ij', A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Outer Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 1., 2.],\n",
       "        [0., 2., 4.],\n",
       "        [0., 3., 6.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([0, 1, 2])\n",
    "b = torch.Tensor([0, 1, 2, 3])\n",
    "\n",
    "torch.einsum('i, j -> ji', a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Batch Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor(4, 3, 2)\n",
    "B = torch.Tensor(4, 2, 5)\n",
    "\n",
    "torch.einsum('bik, bkj -> bij', A, B).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Matrix Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 4., 8.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[0, 1, 2],\n",
    "                  [3, 4, 5],\n",
    "                  [6, 7, 8]])\n",
    "\n",
    "torch.einsum('ii -> i', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([[0, 1, 2],\n",
    "                  [3, 4, 5],\n",
    "                  [6, 7, 8]])\n",
    "\n",
    "torch.einsum('ii -> ', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅳ. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rockt.github.io/2018/04/30/einsum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
